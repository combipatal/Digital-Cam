# FPGA 기반 실시간 디지털 카메라 시스템 프로젝트 분석 보고서

## 1. 프로젝트 개요 (Project Overview)
이 프로젝트는 **FPGA를 이용한 실시간 디지털 카메라 시스템**입니다. OV7670 카메라 모듈로부터 영상 데이터를 입력받아, 사용자의 선택에 따라 다양한 이미지 처리 알고리즘을 실시간으로 적용하고, 그 결과를 VGA 모니터로 출력하는 시스템입니다. 전체 시스템은 Verilog HDL로 설계되었으며, IR 리모컨을 통해 사용자와 상호작용합니다.

---

## 2. 시스템 아키텍처 및 데이터 흐름 (System Architecture & Data Flow)
본 프로젝트는 **파이프라인(Pipeline)** 구조로 설계되어 카메라 입력부터 VGA 출력까지 데이터가 단계적으로 처리됩니다.

1.  **카메라 설정 (Initialization)**:
    - `ov7670_controller` 모듈이 I2C 통신을 이용해 OV7670 카메라의 내부 레지스터를 설정합니다.
    - 출력 포맷은 **VGA (640x480) 해상도, RGB565 컬러 포맷**으로 지정됩니다.

2.  **이미지 캡처 및 축소 (Capture & Decimation)**:
    - `ov7670_capture` 모듈이 카메라에서 출력되는 8비트 병렬 데이터를 2개씩 조합하여 16비트 RGB565 픽셀 데이터로 변환합니다.
    - 동시에, 메모리 사용량과 연산 부담을 줄이기 위해 **2x2 평균값 필터(Averaging Filter)**를 적용하여 원본 640x480 영상을 **320x240** 해상도로 축소(Decimation)합니다.

3.  **프레임 버퍼 저장 (Frame Buffer Storage)**:
    - 축소된 320x240 영상 데이터는 `ov7670_pclk`(카메라 픽셀 클럭)에 맞춰 듀얼 포트 RAM(`frame_buffer_ram`)에 순차적으로 저장됩니다.
    - 이 RAM은 서로 다른 클럭(카메라 쓰기, VGA 읽기)으로 동작하는 비동기 환경을 지원합니다.

4.  **VGA 읽기 및 확대 (VGA Read & Upscaling)**:
    - `vga_640` 모듈은 `clk_25_vga`(VGA 클럭)에 맞춰 표준 640x480@60Hz VGA 타이밍 신호(HSYNC, VSYNC)를 생성합니다.
    - 프레임 버퍼에서 320x240 해상도의 영상을 읽어와 **최근접 이웃 보간법(Nearest-Neighbor Interpolation)** 방식으로 픽셀을 복제하여 **640x480** 해상도로 다시 확대(Upscaling)합니다.

5.  **이미지 처리 (Image Processing)**:
    - 확대된 640x480 영상 데이터 스트림은 `digital_cam_top` 모듈 내의 다양한 이미지 처리 필터로 동시에 전달됩니다.
    - 각 필터는 독립적으로 동작하며, 처리된 결과는 최종 출력 선택을 위해 대기합니다.

6.  **출력 선택 및 표시 (Output Selection & Display)**:
    - `IR_RECEVER` 모듈이 수신한 리모컨 신호에 따라 `active_filter_mode` 값이 변경됩니다.
    - 이 값에 따라 멀티플렉서(MUX)가 원본 영상 또는 특정 필터의 결과 중 하나를 선택하여 최종 VGA 출력으로 보냅니다.

---

## 3. 주요 모듈별 핵심 원리 설명

### 3.1. `ov7670_controller` (카메라 제어)
- **원리**: I2C(Inter-Integrated Circuit) 직렬 통신 프로토콜을 사용하여 카메라 모듈을 제어합니다.
- **동작**: FPGA가 마스터(Master)가 되어 카메라 모듈(슬레이브, Slave)의 특정 주소에 정의된 레지스터 값을 쓰기(Write)하여 해상도, 색상 포맷, 프레임 레이트 등 다양한 설정을 초기화하고 구성합니다.

### 3.2. `IR_RECEVER` (IR 리모컨 수신)
- **원리**: NEC 프로토콜 기반의 적외선 신호를 디코딩합니다.
- **동작**: IR 수신기는 38kHz로 변조된 적외선 신호를 감지합니다. 모듈은 신호의 LOW/HIGH 지속 시간을 측정하여 리더 코드(Leader code), 커스텀 코드(Custom code), 데이터 코드(Data code)를 순차적으로 분석하고, 최종적으로 어떤 버튼이 눌렸는지 식별하는 키 코드를 출력합니다.

### 3.3. `frame_buffer_ram` (메모리 제어)
- **원리**: 듀얼 포트(Dual-Port) RAM을 이용하여 서로 다른 클럭 도메인에서의 동시 읽기/쓰기를 지원합니다. (비동기 FIFO와 유사)
- **주소 할당 및 접근**:
    - **쓰기(Write)**: `ov7670_capture` 모듈이 생성하는 `href`와 `vsync` 신호를 기준으로 픽셀 카운터를 동작시켜 순차적인 쓰기 주소(`wraddress`)를 생성합니다.
    - **읽기(Read)**: `vga_640` 모듈이 생성하는 VGA 화면 좌표(`v_addr`, `h_addr`)를 기반으로 읽기 주소(`rdaddress`)를 생성합니다. 320x240 버퍼를 640x480으로 확대하므로, 주소의 최상위 비트(MSB)를 하나씩 버리는 방식(`h_addr[8:1]`, `v_addr[8:1]`)으로 1/2 스케일의 주소를 계산합니다.

### 3.4. `vga_640` (VGA 신호 생성)
- **원리**: 표준 VESA 타이밍(640x480@60Hz)에 맞춰 수평/수직 카운터를 동작시킵니다.
- **동작**: 25.175MHz 클럭에 맞춰 수평 카운터(`h_count`)와 수직 카운터(`v_count`)를 증가시킵니다. 각 카운터 값이 화면 표시 영역(Active Display Area), 전면 포치(Front Porch), 동기화 펄스(Sync Pulse), 후면 포치(Back Porch) 구간 중 어디에 해당하는지에 따라 `hsync`, `vsync` 신호를 생성하고, 픽셀 데이터 유효 구간을 나타내는 `video_on` 신호를 만듭니다.

### 3.5. 이미지 처리 필터 원리
- **공통 구조**: 대부분의 필터는 3x3 커널(Kernel) 연산을 기반으로 합니다. 이를 위해 2개의 라인 버퍼(Line Buffer)를 사용하여 현재 픽셀 주변의 3x3 픽셀 데이터를 동시에 접근할 수 있는 윈도우를 구성합니다.

- **Grayscale (그레이스케일)**:
    - **원리**: 컬러 이미지를 흑백으로 변환합니다. 사람의 시각이 녹색에 가장 민감한 특성을 반영한 Luma 공식을 사용합니다.
    - **수식**: `Y = 0.299*R + 0.587*G + 0.114*B`. 하드웨어에서는 곱셈 대신 비트 시프트(shift)와 덧셈 연산으로 근사화하여 구현합니다.

- **Gaussian Blur (가우시안 블러)**:
    - **원리**: 이미지의 노이즈를 제거하고 부드럽게 만듭니다. 3x3 가중치 마스크(평균 필터와 유사)를 사용하여 주변 픽셀 값들과의 가중 평균을 계산합니다.

- **Sobel Edge Detection (소벨 엣지 검출)**:
    - **원리**: 이미지의 수평, 수직 방향 밝기 변화율(Gradient)을 계산하여 엣지를 검출합니다.
    - **동작**: 수평 마스크(Gx)와 수직 마스크(Gy)를 각각 3x3 윈도우에 컨볼루션(Convolution)하여 각 방향의 엣지 강도를 계산하고, 두 결과의 크기를 조합(`|Gx| + |Gy|`)하여 최종 엣지 강도를 구합니다.

- **Canny Edge Detection (캐니 엣지 검출)**:
    - **원리**: Sobel보다 더 정교한 엣지 검출 알고리즘으로, 가우시안 필터링 -> Gradient 계산 -> 비최대 억제(Non-maximum suppression) -> 이중 임계값(Double Thresholding)의 단계를 거칩니다. 이 프로젝트에서는 간략화된 버전이 구현되었을 수 있습니다.

- **`rgb_to_hsv` (RGB to HSV 변환)**:
    - **원리**: 색상 표현 모델을 RGB(Red, Green, Blue)에서 HSV(Hue, Saturation, Value)로 변환합니다. HSV는 색상(H), 채도(S), 명도(V)로 색을 표현하여 특정 색상 범위를 검출하는 데 더 용이합니다.
    - **동작**: R, G, B 값 중 최대값(MAX)과 최소값(MIN)을 찾고, 이를 기반으로 V(MAX), S(MAX-MIN / MAX), H(R,G,B 관계에 따른 복잡한 수식)를 순차적으로 계산합니다.

### 3.6. `adaptive_background` (지능형 움직임 감지)
- **궁극적 목표**: 움직이는 객체만 '전경'으로, 정적인 부분은 '배경'으로 구분하여 표시합니다.
- **핵심 기술 1: 이중 학습률 (Dual-Rate Learning)**
    - **빠른 적응 (배경)**: 현재 픽셀이 배경으로 판단되면, `새 배경 = (1-α)*기존 배경 + α*실시간 픽셀` (α=1/16) 공식을 적용하여 조명 변화 같은 환경 변화에 빠르게 적응합니다.
    - **느린 흡수 (전경)**: 전경으로 판단된 픽셀(움직임이 멈춘 객체)에 대해서는 매우 낮은 학습률(α=1/256)을 적용하여, 시간이 지남에 따라 점차 배경의 일부로 흡수되도록 만듭니다.
- **핵심 기술 2: 동적 임계값 (Dynamic Threshold)**
    - **원리**: 고정된 값 대신, 배경 픽셀의 밝기(Luma)에 따라 실시간으로 전경/배경을 구분하는 임계값(Threshold)을 조절합니다.
    - **수식**: `THRESHOLD = (배경 Luma / 2) + MIN_THRESHOLD`
    - **효과**: 밝은 배경에서는 임계값이 높아져 사소한 노이즈를 무시하고, 어두운 배경에서는 임계값이 낮아져 미세한 움직임도 민감하게 감지할 수 있습니다.

---

## 4. 파이프라인 지연 관리 (Pipeline Latency Management)
- **문제점**: 각 이미지 처리 필터는 내부 로직(특히 라인 버퍼)으로 인해 고유의 처리 지연(Latency)을 가집니다. 이로 인해 원본 영상과 각 필터의 출력 영상 간에 시간차가 발생합니다.
- **해결책**: `digital_cam_top` 모듈에서 각 필터의 지연 시간을 미리 계산하고, 해당 시간만큼 원본 영상 및 다른 필터들의 출력을 시프트 레지스터(Shift Register)를 이용해 인위적으로 지연시킵니다. 이를 통해 최종 출력 선택단(MUX)에 도달하는 모든 영상 스트림이 동일한 픽셀 위치를 가리키도록 동기화(Synchronization)합니다.
